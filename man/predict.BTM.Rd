% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/btm.R
\name{predict.BTM}
\alias{predict.BTM}
\title{Predict function for a Biterm Topic Model}
\usage{
\method{predict}{BTM}(object, newdata, type = c("sum_b", "sub_w", "mix"), ...)
}
\arguments{
\item{object}{an object of class BTM as returned by \code{\link{BTM}}}

\item{newdata}{a tokenised data frame containing one row per token with columns doc_id (a context identifier e.g. a tweet id, a document id, a sentence id) and token (of type character with the token)}

\item{type}{character string with the type of prediction. 
Either one of 'sum_b', 'sub_w' or 'mix'. Default is set to 'sum_b' as indicated in the paper, 
indicating to sum over the the expectation of the topic proportions of biterms generated from the document. For the other approaches, please inspect the paper.}

\item{...}{not used}
}
\value{
a matrix containing one row per doc_id (context identifier)
which contains words part of the dictionary of the BTM model and K columns, one for each topic. 
It contains P(z|d), the probability of the topic given the biterms for each context identifier.
}
\description{
Classify new text alongside the biterm topic model.\cr

To infer the topics in a document, it is assumed that the topic proportions of a document 
equals to the expectation of the topic proportions of biterms generated from the document.
}
\examples{
library(udpipe)
data("brussels_reviews_anno", package = "udpipe")
x <- subset(brussels_reviews_anno, language == "nl")
x <- subset(x, xpos \%in\% c("NN", "NNP", "NNS"))
model  <- BTM(x, k = 5, iter = 5, trace = TRUE)
scores <- predict(model, newdata = x, type = "sum_b")
scores <- predict(model, newdata = x, type = "sub_w")
scores <- predict(model, newdata = x, type = "mix")
}
\references{
Xiaohui Yan, Jiafeng Guo, Yanyan Lan, Xueqi Cheng. A Biterm Topic Model For Short Text. WWW2013,
\url{https://github.com/xiaohuiyan/BTM}
}
